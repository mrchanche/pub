{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b27eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dancing in the masquerade, idle truth in plain sight jaded, pop, roll, click, shot, who will I be today or not? But such a tide as moving seems asleep, too full for sound and foam, when that which drew from out the boundless deep turns again home, twilight and evening bell, and after that?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████| 2/2 [00:00<00:00, 207.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dancing in the masquerade, idle truth in plain sight jaded, pop, roll, click, shot, who will I be today or not? But such a tide as moving seems asleep, too full for sound and foam, when that which drew from out the boundless deep turns again home, twilight and evening bell, and after that?\n",
      "\n",
      "### Response:The text provided appears to be a poetic or literary excerpt, possibly from a poem or a piece of prose that uses a stream-of-consciousness style. It does not seem to be a question that requires a factual answer but rather a reflection or a piece of creative writing. The text explores themes of time, change, and the cyclical nature of life, using imagery of the sea and the transition from day to night.\n",
      "\n",
      "The lines \"Dancing in the masquerade, idle truth in plain sight jaded, pop, roll, click, shot, who will I be today or not?\" suggest a contemplation of identity and the mask\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import whisper\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "# Func to free up XPU VRAM from allocator\n",
    "def clearvram():\n",
    "    torch.xpu.memory.empty_cache()\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "# Clear VRAM\n",
    "clearvram()\n",
    "\n",
    "# Load a pre-trained model (e.g., \"base\", \"small\", \"medium\", \"large\")\n",
    "model = whisper.load_model(\"turbo\", device=\"cpu\") \n",
    "\n",
    "# Transcribe your audio file\n",
    "result = model.transcribe(\"test.wav\")\n",
    "\n",
    "print(result[\"text\"])\n",
    "\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\" # Replace with your chosen model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16) # Adjust dtype as needed\n",
    "\n",
    "prompt = result[\"text\"]\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "# Generate text\n",
    "output_ids = model.generate(inputs.input_ids, max_new_tokens=150, num_return_sequences=1)\n",
    "\n",
    "# Decode the generated text\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b267f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import whisper\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "# Func to free up XPU VRAM from allocator\n",
    "def clearvram():\n",
    "    torch.xpu.memory.empty_cache()\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "# Clear VRAM\n",
    "clearvram()\n",
    "\n",
    "# Load a pre-trained model (e.g., \"base\", \"small\", \"medium\", \"large\")\n",
    "model = whisper.load_model(\"turbo\", device=\"cpu\") \n",
    "\n",
    "# Transcribe your audio file\n",
    "result = model.transcribe(\"test.wav\")\n",
    "\n",
    "print(result[\"text\"])\n",
    "\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\" # Replace with your chosen model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16) # Adjust dtype as needed\n",
    "\n",
    "prompt = result[\"text\"]\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "# Generate text\n",
    "output_ids = model.generate(inputs.input_ids, max_new_tokens=150, num_return_sequences=1)\n",
    "\n",
    "# Decode the generated text\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
